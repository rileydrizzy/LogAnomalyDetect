{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 23:29:43.549128: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-06 23:29:43.581176: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-06 23:29:43.581812: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-06 23:29:44.313691: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[nltk_data] Downloading package stopwords to /home/gitpod/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "from functools import partial\n",
    "\n",
    "import nltk\n",
    "import polars as pl\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = tf.config.list_physical_devices()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Log</th><th>Target</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot; 1119803499 20…</td><td>&quot;normal&quot;</td></tr><tr><td>&quot; 1119803105 20…</td><td>&quot;normal&quot;</td></tr><tr><td>&quot; 1121496169 20…</td><td>&quot;normal&quot;</td></tr><tr><td>&quot; 1120968564 20…</td><td>&quot;normal&quot;</td></tr><tr><td>&quot; 1120953205 20…</td><td>&quot;normal&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌───────────────────────────────────┬────────┐\n",
       "│ Log                               ┆ Target │\n",
       "│ ---                               ┆ ---    │\n",
       "│ str                               ┆ str    │\n",
       "╞═══════════════════════════════════╪════════╡\n",
       "│  1119803499 2005.06.26 R03-M0-NC… ┆ normal │\n",
       "│  1119803105 2005.06.26 R04-M0-NE… ┆ normal │\n",
       "│  1121496169 2005.07.15 R06-M0-N6… ┆ normal │\n",
       "│  1120968564 2005.07.09 R26-M0-N0… ┆ normal │\n",
       "│  1120953205 2005.07.09 R27-M0-N7… ┆ normal │\n",
       "└───────────────────────────────────┴────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'dev.gzip'\n",
    "dev_df = pl.read_parquet(file)\n",
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/gitpod/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import get_dataset, get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = get_dataset(file_path= file, batch_size=1,shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'rmnccju rmnccju ras kernel info data store interrupt caused dcbf'],\n",
      "      dtype=object)>, <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'rmnecju rmnecju ras kernel info program interrupt illegal instruction'],\n",
      "      dtype=object)>, <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for word in dev_dataset.take(2):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_vec, voc = get_tokenizer(dev_dataset, sequence_length= 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 26,  26,   3,   4,   5,  35,  75,  25,  95, 242,   0,   0,   0,\n",
       "          0,   0]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = token_vec(['rmnccju rmnccju ras kernel info data store interrupt caused dcbf'])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ds = dev_dataset.map(lambda text,label: text)\n",
    "sequence_length = 10\n",
    "tokenizer_layer = tf.keras.layers.TextVectorization(split= 'whitespace', output_mode= 'int',\n",
    "                                              output_sequence_length= sequence_length)\n",
    "tokenizer_layer.adapt(log_ds)\n",
    "vocab_size = tokenizer_layer.vocabulary_size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "log-anaomly-Z6xKN3XP-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
